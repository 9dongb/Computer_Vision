{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"E-gQx1CoeVr7","executionInfo":{"status":"ok","timestamp":1700496651962,"user_tz":-540,"elapsed":5901,"user":{"displayName":"구동빈","userId":"02842982751778039037"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader\n","import pdb\n","\n","# 같은 결과를 출력하기 위해 seed 값 고정\n","torch.manual_seed(0)\n","torch.cuda.manual_seed(0)"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"P87eU8gceVsD","executionInfo":{"status":"ok","timestamp":1700496664444,"user_tz":-540,"elapsed":4,"user":{"displayName":"구동빈","userId":"02842982751778039037"}}},"outputs":[],"source":["# MNIST 데이터를 로드하기 위한 트랜스폼 정의\n","transform = transforms.Compose([\n","    transforms.ToTensor(), # 이미지를 PyTorch Tensor로 변환\n","    transforms.Normalize((0.5,), (0.5,)) # 픽셀 값의 범위를 -1에서 1로 정규화\n","])\n","\n","# 2개의 층으로 이루어진 MLP 모델 정의\n","class MLP(nn.Module):\n","    def __init__(self): # 생성자\n","        super(MLP, self).__init__() # 상속 받기\n","        self.fc1 = nn.Linear(28*28, 64) # 첫 번째 fully connected layer (입력: 28*28, 출력: 64)\n","        self.fc2 = nn.Linear(64, 10) # 두 번째 fully connected layer (입력: 64, 출력: 10)\n","\n","    def forward(self, x):\n","        # 데이터의 shape을 변경 (Batch*784로 변경) -1 를 사용하는 경우 그 값을 자동으로 계산해줌\n","        x = x.view(-1, 28*28) # 이미지를 1차원으로 펼침\n","\n","        x = self.fc1(x) # 첫 번째 fully connected layer 적용\n","        x = F.relu(x) # ReLU 활성화 함수를 적용\n","        x = self.fc2(x) # 두 번째 fully connected layer 적용\n","\n","        # softmax : 모든 값을 0 ~ 1 사이로 Normalize하며, 모든 값들이 1로 되게 만드는 함수\n","        # Data의 shape은 batch*dim으로 구성, 따라서 2번째 차원에 활성화 함수를 적용\n","        return F.log_softmax(x, dim=1)"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"zTiq7HIkeVsE","executionInfo":{"status":"ok","timestamp":1700496669250,"user_tz":-540,"elapsed":3,"user":{"displayName":"구동빈","userId":"02842982751778039037"}}},"outputs":[],"source":["# 모델 훈련 함수\n","def train(model, device, train_loader, optimizer):\n","    model.train()\n","    for _, (data, target) in enumerate(train_loader):\n","        data, target = data.to(device), target.to(device)\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = criterion(output, target)\n","        loss.backward()\n","        optimizer.step()\n","\n","# 모델 평가 함수\n","def test(model, device, test_loader):\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","    with torch.no_grad():\n","        for data, target in test_loader:\n","            data, target = data.to(device), target.to(device)\n","            output = model(data)\n","            test_loss += criterion(output, target).item()  # 배치 손실 합산\n","            pred = output.argmax(dim=1, keepdim=True)  # 가장 높은 값을 가진 인덱스를 가져옴\n","            correct += pred.eq(target.view_as(pred)).sum().item()\n","\n","    test_loss /= len(test_loader.dataset)\n","    print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} ({100. * correct / len(test_loader.dataset):.2f}%)')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3IN1xyqLeVsF","outputId":"21e73469-234b-4afb-ebed-4149da23a9a9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9912422/9912422 [00:00<00:00, 94969850.57it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28881/28881 [00:00<00:00, 85668807.51it/s]"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["\n","100%|██████████| 1648877/1648877 [00:00<00:00, 22887949.21it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 4542/4542 [00:00<00:00, 7872119.33it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n","\n","[batch_size : 64]\n","- Learning rate 0.1 \n","\n","Test set: Average loss: 0.0020, Accuracy: 1990/10000 (19.90%)\n","\n","Test set: Average loss: 0.0023, Accuracy: 1009/10000 (10.09%)\n","\n","Test set: Average loss: 0.0023, Accuracy: 974/10000 (9.74%)\n","\n","Test set: Average loss: 0.0023, Accuracy: 1135/10000 (11.35%)\n","\n","Test set: Average loss: 0.0023, Accuracy: 1135/10000 (11.35%)\n","- Learning rate 0.01 \n","\n","Test set: Average loss: 0.0003, Accuracy: 9150/10000 (91.50%)\n","\n","Test set: Average loss: 0.0003, Accuracy: 9048/10000 (90.48%)\n","\n","Test set: Average loss: 0.0002, Accuracy: 9309/10000 (93.09%)\n","\n","Test set: Average loss: 0.0002, Accuracy: 9296/10000 (92.96%)\n","\n","Test set: Average loss: 0.0002, Accuracy: 9275/10000 (92.75%)\n","- Learning rate 0.001 \n","\n","Test set: Average loss: 0.0003, Accuracy: 9248/10000 (92.48%)\n","\n","Test set: Average loss: 0.0002, Accuracy: 9426/10000 (94.26%)\n","\n","Test set: Average loss: 0.0002, Accuracy: 9463/10000 (94.63%)\n","\n","Test set: Average loss: 0.0001, Accuracy: 9559/10000 (95.59%)\n","\n","Test set: Average loss: 0.0001, Accuracy: 9614/10000 (96.14%)\n","[batch_size : 128]\n","- Learning rate 0.1 \n","\n","Test set: Average loss: 0.0020, Accuracy: 2121/10000 (21.21%)\n","\n","Test set: Average loss: 0.0021, Accuracy: 2086/10000 (20.86%)\n","\n","Test set: Average loss: 0.0022, Accuracy: 1642/10000 (16.42%)\n","\n","Test set: Average loss: 0.0023, Accuracy: 1034/10000 (10.34%)\n","\n","Test set: Average loss: 0.0023, Accuracy: 960/10000 (9.60%)\n","- Learning rate 0.01 \n","\n","Test set: Average loss: 0.0002, Accuracy: 9314/10000 (93.14%)\n","\n","Test set: Average loss: 0.0002, Accuracy: 9318/10000 (93.18%)\n","\n","Test set: Average loss: 0.0002, Accuracy: 9298/10000 (92.98%)\n","\n","Test set: Average loss: 0.0002, Accuracy: 9481/10000 (94.81%)\n","\n","Test set: Average loss: 0.0002, Accuracy: 9404/10000 (94.04%)\n","- Learning rate 0.001 \n","\n","Test set: Average loss: 0.0003, Accuracy: 9123/10000 (91.23%)\n","\n","Test set: Average loss: 0.0002, Accuracy: 9280/10000 (92.80%)\n","\n","Test set: Average loss: 0.0002, Accuracy: 9378/10000 (93.78%)\n","\n","Test set: Average loss: 0.0002, Accuracy: 9481/10000 (94.81%)\n","\n","Test set: Average loss: 0.0002, Accuracy: 9543/10000 (95.43%)\n","[batch_size : 256]\n","- Learning rate 0.1 \n","\n","Test set: Average loss: 0.0021, Accuracy: 1976/10000 (19.76%)\n","\n","Test set: Average loss: 0.0020, Accuracy: 2113/10000 (21.13%)\n","\n","Test set: Average loss: 0.0021, Accuracy: 2122/10000 (21.22%)\n","\n","Test set: Average loss: 0.0020, Accuracy: 1922/10000 (19.22%)\n","\n","Test set: Average loss: 0.0020, Accuracy: 1918/10000 (19.18%)\n","- Learning rate 0.01 \n","\n","Test set: Average loss: 0.0003, Accuracy: 9179/10000 (91.79%)\n","\n","Test set: Average loss: 0.0002, Accuracy: 9260/10000 (92.60%)\n","\n","Test set: Average loss: 0.0002, Accuracy: 9315/10000 (93.15%)\n","\n","Test set: Average loss: 0.0002, Accuracy: 9318/10000 (93.18%)\n"]}],"source":["if __name__ == '__main__':\n","\n","    train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n","    test_dataset = datasets.MNIST('./data', train=False, transform=transform)\n","\n","    n_epoch = 5\n","    batch_size = 64\n","    learning_rate = 0.1\n","\n","    bs = [64, 128, 256]\n","    lr = [0.1, 0.01, 0.001]\n","\n","    for batch_s in bs: # 인덱스와, 값을 반환\n","        print(f'[batch_size : {batch_s}]')\n","        train_loader = DataLoader(train_dataset, batch_size=batch_s, shuffle=True)\n","        test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)\n","\n","        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","        criterion = nn.CrossEntropyLoss()\n","\n","        for learning_rate in lr:\n","            print(f'- Learning rate {learning_rate} ')\n","            model = MLP()\n","            optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","            model.to(device)\n","            for epoch in range(n_epoch):\n","                train(model, device, train_loader, optimizer)\n","                test(model, device, test_loader)\n","\n","\n","    # train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","    # test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)\n","\n","    # device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","    # model = MLP()\n","    # criterion = nn.CrossEntropyLoss()\n","\n","    # optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","    # model.to(device)\n","    # for epoch in range(n_epoch):\n","    #     train(model, device, train_loader, optimizer)\n","    #     test(model, device, test_loader)"]},{"cell_type":"code","source":[],"metadata":{"id":"TtMrj8fHgAiB"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"cv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}